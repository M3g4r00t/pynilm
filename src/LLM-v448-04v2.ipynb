{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 448\n",
    "n_components = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las variables independientes (X_train) sin cabecera desde archivo\n",
    "X_train = np.loadtxt(f'../data/v8.2/transformed_train_data_comp_{n_components}.csv', delimiter=',')\n",
    "\n",
    "# Cargar las variables dependientes (y_train) con cabecera desde archivo\n",
    "y_train = pd.read_csv(f'../data/train_value_min_label_windows_{window_size}_llm.csv')\n",
    "\n",
    "# Cargar el conjunto de test (X_test sin cabeceras y y_test con cabeceras)\n",
    "X_test = np.loadtxt(f'../data/v8.2/transformed_test_data_comp_{n_components}.csv', delimiter=',')\n",
    "y_test = pd.read_csv(f'../data/test_value_min_label_windows_{window_size}_llm.csv')\n",
    "\n",
    "# Eliminar la columna \"row\" que es solo un índice\n",
    "y_train = y_train.drop(columns=['row'])\n",
    "y_test = y_test.drop(columns=['row'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar los datos de entrenamiento y test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the class for each appliance\n",
    "def generate_class(row, appliance):\n",
    "    appliance_value = row[appliance]\n",
    "    other_values = row.drop(appliance).values  # Values for the other appliances\n",
    "\n",
    "    if appliance_value == 0 and not any(other_values):\n",
    "        return 'off'\n",
    "    elif appliance_value == 1 and not any(other_values):\n",
    "        return 'on'\n",
    "    elif appliance_value == 0 and any(other_values):\n",
    "        return 'off w int'\n",
    "    elif appliance_value == 1 and any(other_values):\n",
    "        return 'on w int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Class       Window_Size  Accuracy  F1_Macro  F1_Weighted  \\\n",
      "0               Sockets01  Your_Window_Size  0.927341  0.802738     0.925629   \n",
      "1               Sockets02  Your_Window_Size  0.937079  0.937025     0.937189   \n",
      "2                 Light01  Your_Window_Size  0.936330  0.936272     0.936443   \n",
      "3          CE appliance01  Your_Window_Size  0.862172  0.810707     0.854870   \n",
      "4                Fridge01  Your_Window_Size  0.839700  0.807857     0.834454   \n",
      "5   Waste disposal unit01  Your_Window_Size  0.937079  0.937025     0.937189   \n",
      "6           Dish washer01  Your_Window_Size  0.928839  0.621588     0.926627   \n",
      "7      Electric furnace01  Your_Window_Size  0.931086  0.622492     0.933640   \n",
      "8                 Light02  Your_Window_Size  0.807865  0.754077     0.795794   \n",
      "9               Sockets03  Your_Window_Size  0.888764  0.621984     0.898512   \n",
      "10                Light03  Your_Window_Size  0.937079  0.937025     0.937189   \n",
      "11            Microwave01  Your_Window_Size  0.934831  0.624030     0.934335   \n",
      "12                Light04  Your_Window_Size  0.847191  0.799468     0.841448   \n",
      "13          Smoke alarm01  Your_Window_Size  0.937079  0.937025     0.937189   \n",
      "14                Light05  Your_Window_Size  0.823221  0.747579     0.816959   \n",
      "15              Unknown01  Your_Window_Size  0.930712  0.653104     0.931621   \n",
      "16              Sockets04  Your_Window_Size  0.917603  0.617624     0.925725   \n",
      "17              Sockets05  Your_Window_Size  0.919850  0.618306     0.924117   \n",
      "18         Washer dryer01  Your_Window_Size  0.934082  0.871821     0.934221   \n",
      "19         Washer dryer02  Your_Window_Size  0.926217  0.867364     0.925413   \n",
      "\n",
      "    AUC_Macro  AUC_Weighted  \n",
      "0    0.953792      0.943165  \n",
      "1    0.945377      0.945377  \n",
      "2    0.945366      0.945366  \n",
      "3    0.912441      0.925097  \n",
      "4    0.913710      0.919149  \n",
      "5    0.945377      0.945377  \n",
      "6    0.932441      0.943245  \n",
      "7    0.945294      0.945294  \n",
      "8    0.895572      0.904684  \n",
      "9    0.906799      0.938434  \n",
      "10   0.945377      0.945377  \n",
      "11   0.954226      0.945057  \n",
      "12   0.916313      0.921204  \n",
      "13   0.945377      0.945377  \n",
      "14   0.899456      0.908456  \n",
      "15   0.836525      0.944789  \n",
      "16   0.944628      0.944628  \n",
      "17   0.888807      0.942811  \n",
      "18   0.962812      0.944879  \n",
      "19   0.957140      0.942863  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize DataFrames to store results\n",
    "metrics_df = pd.DataFrame(columns=[\n",
    "    \"Class\", \"Window_Size\", \"Accuracy\", \"F1_Macro\", \"F1_Weighted\", \"AUC_Macro\", \"AUC_Weighted\"\n",
    "])\n",
    "all_reports_df = pd.DataFrame()\n",
    "all_confusion_matrices_df = pd.DataFrame()\n",
    "\n",
    "# Bucle para realizar clasificación binaria para cada columna (clase)\n",
    "for col in y_train.columns:\n",
    "    # Create the class labels for each appliance\n",
    "    y_train_bin = y_train.apply(lambda row: generate_class(row, col), axis=1)\n",
    "    y_test_bin = y_test.apply(lambda row: generate_class(row, col), axis=1)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_bin_encoded = label_encoder.fit_transform(y_train_bin)\n",
    "    y_test_bin_encoded = label_encoder.transform(y_test_bin)\n",
    "\n",
    "    # Get unique classes for the current appliance\n",
    "    unique_classes = np.unique(y_train_bin_encoded)\n",
    "\n",
    "    # Handle class imbalance by computing sample weights\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train_bin_encoded)\n",
    "    class_weight_dict = {cls: weight for cls, weight in zip(unique_classes, class_weights)}\n",
    "    sample_weight = np.array([class_weight_dict[cls] for cls in y_train_bin_encoded])\n",
    "\n",
    "    # Train XGBoost with class weights\n",
    "    xgb_clf = XGBClassifier(\n",
    "        eval_metric='mlogloss',\n",
    "        tree_method='hist',\n",
    "        device='cuda'\n",
    "    )\n",
    "\n",
    "    xgb_clf.fit(X_train_scaled, y_train_bin_encoded, sample_weight=sample_weight)\n",
    "\n",
    "    # Create mapping for target names based on the fitted label encoder\n",
    "    class_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_bin = xgb_clf.predict(X_test_scaled)\n",
    "    y_pred_proba = xgb_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "    # Verificar que haya más de una clase en el conjunto de entrenamiento\n",
    "    if len(np.unique(y_test_bin_encoded)) > 1:\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test_bin_encoded, y_pred_bin)\n",
    "        f1_macro = f1_score(y_test_bin_encoded, y_pred_bin, average=\"macro\")\n",
    "        f1_weighted = f1_score(y_test_bin_encoded, y_pred_bin, average=\"weighted\")\n",
    "\n",
    "        # Check if there are more than two classes to calculate AUC\n",
    "        if len(np.unique(y_test_bin_encoded)) > 2:\n",
    "            auc_macro = roc_auc_score(y_test_bin_encoded, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_weighted = roc_auc_score(y_test_bin_encoded, y_pred_proba, multi_class=\"ovr\", average=\"weighted\")\n",
    "        else:\n",
    "            # If only two classes, calculate AUC differently\n",
    "            auc_macro = roc_auc_score(y_test_bin_encoded, y_pred_proba[:, 1])  # Use probabilities of the positive class\n",
    "            auc_weighted = auc_macro\n",
    "\n",
    "        # Get unique classes in the predictions\n",
    "        unique_pred_classes = np.unique(y_pred_bin)\n",
    "\n",
    "        # Create the classification report using the unique classes found\n",
    "        report = classification_report(\n",
    "            y_test_bin_encoded,\n",
    "            y_pred_bin,\n",
    "            target_names=[class_mapping[label] for label in unique_pred_classes],\n",
    "            labels=unique_pred_classes,\n",
    "            output_dict=True\n",
    "        )\n",
    "\n",
    "        cm = confusion_matrix(y_test_bin_encoded, y_pred_bin)\n",
    "\n",
    "        # Save results to DataFrame\n",
    "        new_metrics_row = {\n",
    "            \"Class\": col,\n",
    "            \"Window_Size\": \"Your_Window_Size\",  # Replace with actual window size variable if available\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1_Macro\": f1_macro,\n",
    "            \"F1_Weighted\": f1_weighted,\n",
    "            \"AUC_Macro\": auc_macro,\n",
    "            \"AUC_Weighted\": auc_weighted\n",
    "        }\n",
    "\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([new_metrics_row])], ignore_index=True)\n",
    "\n",
    "        # Append classification report and confusion matrix to combined DataFrames\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.insert(0, \"Class\", col)\n",
    "        all_reports_df = pd.concat([all_reports_df, report_df], ignore_index=True)\n",
    "\n",
    "        cm_df = pd.DataFrame(cm)\n",
    "        cm_df.insert(0, \"Class\", col)\n",
    "        all_confusion_matrices_df = pd.concat([all_confusion_matrices_df, cm_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Display or save the results\n",
    "print(metrics_df)\n",
    "metrics_df.to_csv(f\"../data/metrics_results_{window_size}_{n_components}.csv\", index=False)\n",
    "all_reports_df.to_csv(f\"../data/combined_classification_reports_{window_size}_{n_components}.csv\", index=False)\n",
    "all_confusion_matrices_df.to_csv(f\"../data/combined_confusion_matrices_{window_size}_{n_components}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
