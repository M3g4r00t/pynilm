{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verificar que TensorFlow puede detectar la GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el DataFrame\n",
    "df_train = pd.read_csv('../data/train_value_min_label_windows_896.csv')\n",
    "df_test = pd.read_csv('../data/test_value_min_label_windows_896.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n",
      "94781440/94765736 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Modelo preentrenado (usar VGG16 o ResNet50)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar y procesar imágenes\n",
    "def load_and_process_image(image_folder, img_name):\n",
    "    img_r_path = os.path.join(image_folder, f\"{img_name}_mains.png\")\n",
    "    img_g_path = os.path.join(image_folder, f\"{img_name}_amplitude_spectrum.png\")\n",
    "    img_b_path = os.path.join(image_folder, f\"{img_name}_phase_spectrum.png\")\n",
    "    \n",
    "    img_r = Image.open(img_r_path).convert('L')\n",
    "    img_g = Image.open(img_g_path).convert('L')\n",
    "    img_b = Image.open(img_b_path).convert('L')\n",
    "    \n",
    "    img_r = img_r.resize((224, 224))\n",
    "    img_g = img_g.resize((224, 224))\n",
    "    img_b = img_b.resize((224, 224))\n",
    "    \n",
    "    img_rgb = Image.merge(\"RGB\", (img_r, img_g, img_b))\n",
    "    img_array = img_to_array(img_rgb)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = resnet_preprocess(img_array)  # Normalizar las imágenes en el rango esperado por VGG16\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer características\n",
    "features = []\n",
    "for img_name in df_train['row']:\n",
    "    img_array = load_and_process_image('../data/v3/window_size_896/train/all',img_name)\n",
    "    feature = model.predict(img_array)\n",
    "    features.append(feature.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a array numpy\n",
    "features_train = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer características\n",
    "features = []\n",
    "for img_name in df_test['row']:\n",
    "    img_array = load_and_process_image('../data/v3/window_size_896/test/all',img_name)\n",
    "    feature = model.predict(img_array)\n",
    "    features.append(feature.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a array numpy\n",
    "features_test = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las columnas de etiquetas\n",
    "labels_train = df_train.drop(columns=['row'])\n",
    "labels_test = df_test.drop(columns=['row'])\n",
    "# Diccionario para almacenar los resultados\n",
    "appliances = labels_train.columns\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo para guardar los resultados\n",
    "results_file = '../data/v3/model_results_window_size_896_resnet.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar resultados existentes\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para guardar los resultados\n",
    "def save_results(results):\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [6:24:54<00:00, 1154.73s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar modelos para cada columna\n",
    "for a in tqdm(appliances):\n",
    "    if a in results:\n",
    "        print(f\"Results for column {a} already exist. Skipping training.\")\n",
    "        continue\n",
    "\n",
    "    y_train = labels_train[a]\n",
    "    y_test = labels_test[a]\n",
    "    X_train = features_train\n",
    "    X_test = features_test\n",
    "    \n",
    "    # MLP\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(128, 64),  # Configuración con dos capas ocultas\n",
    "                        max_iter=500,\n",
    "                        learning_rate_init=0.001,\n",
    "                        solver='adam',\n",
    "                        alpha=0.01,\n",
    "                        random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    y_pred_mlp = mlp.predict(X_test_scaled)\n",
    "    \n",
    "    # XGBoost\n",
    "    #xgb = XGBClassifier(random_state=42)\n",
    "    #xgb.fit(X_train, y_train)\n",
    "    #y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "    # Evaluación\n",
    "    metrics = {}\n",
    "    \n",
    "    # Función para manejar errores en AUC\n",
    "    def safe_roc_auc_score(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except ValueError as e:\n",
    "            #print(f\"ROC AUC score error: {e}\")\n",
    "            return np.nan  # Retorna NaN si ocurre un error\n",
    "        \n",
    "    metrics['MLP'] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred_mlp),\n",
    "        'auc': safe_roc_auc_score(y_test, y_pred_mlp),\n",
    "        'f1_score': f1_score(y_test, y_pred_mlp),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred_mlp).tolist()  # Convertir a lista para guardar en JSON\n",
    "    }\n",
    "    \n",
    "    #metrics['XGBoost'] = {\n",
    "    #    'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    #    'auc': safe_roc_auc_score(y_test, y_pred_xgb),\n",
    "    #    'f1_score': f1_score(y_test, y_pred_xgb),\n",
    "    #    'confusion_matrix': confusion_matrix(y_test, y_pred_xgb).tolist()  # Convertir a lista para guardar en JSON\n",
    "    #}\n",
    "    \n",
    "    results[a] = metrics\n",
    "\n",
    "    # Guardar resultados después de cada columna\n",
    "    save_results(results) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: Sockets01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9813\n",
      "    AUC: 0.4989\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1310, 3], [22, 0]]\n",
      "Column: Sockets02\n",
      "  Model: MLP\n",
      "    Accuracy: 1.0000\n",
      "    AUC: nan\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1335]]\n",
      "Column: Light01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9985\n",
      "    AUC: nan\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1333, 2], [0, 0]]\n",
      "Column: CE appliance01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9026\n",
      "    AUC: 0.9096\n",
      "    F1 Score: 0.9046\n",
      "    Confusion Matrix:\n",
      "[[589, 12], [118, 616]]\n",
      "Column: Fridge01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.8629\n",
      "    AUC: 0.8510\n",
      "    F1 Score: 0.8235\n",
      "    Confusion Matrix:\n",
      "[[725, 68], [115, 427]]\n",
      "Column: Waste disposal unit01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9985\n",
      "    AUC: nan\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1333, 2], [0, 0]]\n",
      "Column: Dish washer01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9910\n",
      "    AUC: 0.4992\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1323, 2], [10, 0]]\n",
      "Column: Electric furnace01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9963\n",
      "    AUC: nan\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1330, 5], [0, 0]]\n",
      "Column: Light02\n",
      "  Model: MLP\n",
      "    Accuracy: 0.7985\n",
      "    AUC: 0.5996\n",
      "    F1 Score: 0.3455\n",
      "    Confusion Matrix:\n",
      "[[995, 33], [236, 71]]\n",
      "Column: Sockets03\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9723\n",
      "    AUC: 0.5476\n",
      "    F1 Score: 0.0976\n",
      "    Confusion Matrix:\n",
      "[[1296, 21], [16, 2]]\n",
      "Column: Light03\n",
      "  Model: MLP\n",
      "    Accuracy: 1.0000\n",
      "    AUC: nan\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1335]]\n",
      "Column: Microwave01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9850\n",
      "    AUC: 0.5515\n",
      "    F1 Score: 0.1667\n",
      "    Confusion Matrix:\n",
      "[[1313, 3], [17, 2]]\n",
      "Column: Light04\n",
      "  Model: MLP\n",
      "    Accuracy: 0.8195\n",
      "    AUC: 0.6411\n",
      "    F1 Score: 0.4356\n",
      "    Confusion Matrix:\n",
      "[[1001, 58], [183, 93]]\n",
      "Column: Smoke alarm01\n",
      "  Model: MLP\n",
      "    Accuracy: 1.0000\n",
      "    AUC: nan\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1335]]\n",
      "Column: Light05\n",
      "  Model: MLP\n",
      "    Accuracy: 0.8584\n",
      "    AUC: 0.6049\n",
      "    F1 Score: 0.3368\n",
      "    Confusion Matrix:\n",
      "[[1098, 43], [146, 48]]\n",
      "Column: Unknown01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9850\n",
      "    AUC: 0.5515\n",
      "    F1 Score: 0.1667\n",
      "    Confusion Matrix:\n",
      "[[1313, 3], [17, 2]]\n",
      "Column: Sockets04\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9461\n",
      "    AUC: nan\n",
      "    F1 Score: 0.0000\n",
      "    Confusion Matrix:\n",
      "[[1263, 72], [0, 0]]\n",
      "Column: Sockets05\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9828\n",
      "    AUC: 0.5443\n",
      "    F1 Score: 0.1481\n",
      "    Confusion Matrix:\n",
      "[[1310, 3], [20, 2]]\n",
      "Column: Washer dryer01\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9790\n",
      "    AUC: 0.6053\n",
      "    F1 Score: 0.3333\n",
      "    Confusion Matrix:\n",
      "[[1300, 2], [26, 7]]\n",
      "Column: Washer dryer02\n",
      "  Model: MLP\n",
      "    Accuracy: 0.9738\n",
      "    AUC: 0.6110\n",
      "    F1 Score: 0.3396\n",
      "    Confusion Matrix:\n",
      "[[1291, 4], [31, 9]]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar resultados\n",
    "for column, metrics in results.items():\n",
    "    print(f\"Column: {column}\")\n",
    "    for model_name, scores in metrics.items():\n",
    "        print(f\"  Model: {model_name}\")\n",
    "        print(f\"    Accuracy: {scores['accuracy']:.4f}\")\n",
    "        print(f\"    AUC: {scores['auc']:.4f}\")\n",
    "        print(f\"    F1 Score: {scores['f1_score']:.4f}\")\n",
    "        print(f\"    Confusion Matrix:\\n{scores['confusion_matrix']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilmtk-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
