{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 14\n",
    "n_components = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las variables independientes (X_train) sin cabecera desde archivo\n",
    "X_train = np.loadtxt(f'../data/v10/transformed_train_data_comp_{n_components}.csv', delimiter=',')\n",
    "\n",
    "# Cargar las variables dependientes (y_train) con cabecera desde archivo\n",
    "y_train = pd.read_csv(f'../data/train_value_min_label_windows_{window_size}_llm.csv')\n",
    "\n",
    "# Cargar el conjunto de test (X_test sin cabeceras y y_test con cabeceras)\n",
    "X_test = np.loadtxt(f'../data/v10/transformed_test_data_comp_{n_components}.csv', delimiter=',')\n",
    "y_test = pd.read_csv(f'../data/test_value_min_label_windows_{window_size}_llm.csv')\n",
    "\n",
    "# Eliminar la columna \"row\" que es solo un índice\n",
    "y_train = y_train.drop(columns=['row'])\n",
    "y_test = y_test.drop(columns=['row'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar los datos de entrenamiento y test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the class for each appliance\n",
    "def generate_class(row, appliance):\n",
    "    appliance_value = row[appliance]\n",
    "    other_values = row.drop(appliance).values  # Values for the other appliances\n",
    "\n",
    "    if appliance_value == 0 and not any(other_values):\n",
    "        return 'off'\n",
    "    elif appliance_value == 1 and not any(other_values):\n",
    "        return 'on'\n",
    "    elif appliance_value == 0 and any(other_values):\n",
    "        return 'off w int'\n",
    "    elif appliance_value == 1 and any(other_values):\n",
    "        return 'on w int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (2526110649.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    eval_metric='mlogloss',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Bucle para realizar clasificación binaria para cada columna (clase)\n",
    "for col in y_train.columns:\n",
    "    # Create the class labels for each appliance\n",
    "    y_train_bin = y_train.apply(lambda row: generate_class(row, col), axis=1)\n",
    "    y_test_bin = y_test.apply(lambda row: generate_class(row, col), axis=1)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_bin_encoded = label_encoder.fit_transform(y_train_bin)\n",
    "    y_test_bin_encoded = label_encoder.transform(y_test_bin)\n",
    "\n",
    "    # Get unique classes for the current appliance\n",
    "    unique_classes = np.unique(y_train_bin_encoded)\n",
    "    \n",
    "    # Handle class imbalance by computing sample weights\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train_bin_encoded)\n",
    "    class_weight_dict = {cls: weight for cls, weight in zip(unique_classes, class_weights)}\n",
    "    sample_weight = np.array([class_weight_dict[cls] for cls in y_train_bin_encoded])\n",
    "    \n",
    "    # Train XGBoost with class weights\n",
    "    xgb_clf = XGBClassifier(\n",
    "        eval_metric='mlogloss',\n",
    "        tree_method='hist',\n",
    "        device='cuda'\n",
    "    )\n",
    "\n",
    "    xgb_clf.fit(X_train_scaled, y_train_bin_encoded, sample_weight=sample_weight)\n",
    "\n",
    "    # Create mapping for target names based on the fitted label encoder\n",
    "    class_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_bin = xgb_clf.predict(X_test_scaled)\n",
    "    y_pred_proba = xgb_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "    # Verificar que haya más de una clase en el conjunto de entrenamiento\n",
    "    if len(np.unique(y_test_bin_encoded)) > 1:\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test_bin_encoded, y_pred_bin)\n",
    "        f1_macro = f1_score(y_test_bin_encoded, y_pred_bin, average=\"macro\")\n",
    "        f1_weighted = f1_score(y_test_bin_encoded, y_pred_bin, average=\"weighted\")\n",
    "        # Check if there are more than two classes to calculate AUC\n",
    "        if len(np.unique(y_test_bin_encoded)) > 2:\n",
    "            auc_macro = roc_auc_score(y_test_bin_encoded, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_weighted = roc_auc_score(y_test_bin_encoded, y_pred_proba, multi_class=\"ovr\", average=\"weighted\")\n",
    "        else:\n",
    "            # If only two classes, calculate AUC differently\n",
    "            auc_macro = roc_auc_score(y_test_bin_encoded, y_pred_proba[:, 1])  # Use probabilities of the positive class\n",
    "            auc_weighted = auc_macro\n",
    "\n",
    "        \n",
    "        # Get unique classes in the predictions\n",
    "        unique_pred_classes = np.unique(y_pred_bin)\n",
    "\n",
    "        # Create the classification report using the unique classes found\n",
    "        report = classification_report(\n",
    "            y_test_bin_encoded, \n",
    "            y_pred_bin, \n",
    "            target_names=[class_mapping[label] for label in unique_pred_classes],\n",
    "            labels=unique_pred_classes\n",
    "        )\n",
    "        cm = confusion_matrix(y_test_bin_encoded, y_pred_bin)\n",
    "\n",
    "        # Mostrar resultados\n",
    "        print(f\"Resultados para la clase {col}:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
    "        print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
    "        print(f\"AUC (macro): {auc_macro:.4f}\")\n",
    "        print(f\"AUC (weighted): {auc_weighted:.4f}\")\n",
    "        print(\"Classification Report:\\n\", report)\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
